{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cea1706c",
   "metadata": {},
   "source": [
    "# L2 Clause Pipeline â€” Executable Reference\n",
    "\n",
    "This notebook wires the deterministic L2 pieces together: candidate extraction, normalization, and validation.\n",
    "Adapter (LLM) is optional and must be opt-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409521ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: ensure repo root on sys.path for imports\n",
    "import os, sys, json\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "from level2 import clause_extractor, normalizer, validator\n",
    "from level2.llm_adapter import adapter as llm_adapter\n",
    "\n",
    "INTENTS = [\n",
    "    'investigate',\n",
    "    'execute',\n",
    "    'summarize',\n",
    "    'ops',\n",
    "]\n",
    "\n",
    "CLAUSE_FIELDS = ['entity','operation','metric','time_window','environment','condition','constraint','output_format']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62368e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_pipeline(utterance: str, intent: str, use_adapter: bool = False) -> dict:\n",
    "    \"\"\"Run the L2 deterministic pipeline over an utterance.\n",
    "\n",
    "    Returns the L2 output schema (dict).\n",
    "    \"\"\"\n",
    "    if intent not in INTENTS:\n",
    "        raise ValueError(f'unknown intent: {intent}')\n",
    "\n",
    "    adapter_result = {}\n",
    "    if use_adapter:\n",
    "        adapter_result = llm_adapter.extract_clauses(utterance) or {}\n",
    "\n",
    "    clauses, detectors = clause_extractor.extract_candidates(utterance, use_adapter=use_adapter, adapter_result=adapter_result)\n",
    "    normalized = normalizer.normalize_clauses(clauses)\n",
    "    decision_state, details, ambiguity = validator.validate(normalized, intent)\n",
    "\n",
    "    decision_trace = {\n",
    "        'detectors_fired': detectors,\n",
    "        'hard_rules_failed': details.get('hard_rules_failed', []),\n",
    "        'soft_rules_passed': details.get('soft_rules_passed', []),\n",
    "        'alternatives_eliminated': {},\n",
    "    }\n",
    "\n",
    "    out = {\n",
    "        'utterance': utterance,\n",
    "        'intent': intent,\n",
    "        'clauses': normalized,\n",
    "        'first_pass': 'success' if decision_state == 'accepted' else ('partial' if decision_state == 'needs_clarification' else 'failure'),\n",
    "        'ambiguity_report': ambiguity,\n",
    "        'decision_state': decision_state,\n",
    "        'decision_trace': decision_trace,\n",
    "        'metadata': {\n",
    "            'timestamp': __import__('datetime').datetime.utcnow().isoformat() + 'Z',\n",
    "            'adapter_used': bool(use_adapter),\n",
    "            'adapter_confidence': None,\n",
    "        },\n",
    "    }\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76adb606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example runs\n",
    "samples = [\n",
    "    (\"Restart web-01 in prod immediately\", 'execute'),\n",
    "    (\"Show CPU and memory for web-01 for the last 5m\", 'investigate'),\n",
    "    (\"Delete db-02 in prod\", 'execute'),\n",
    "]\n",
    "\n",
    "for utt, intent in samples:\n",
    "    result = l2_pipeline(utt, intent, use_adapter=False)\n",
    "    print('---')\n",
    "    print(utt)\n",
    "    print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99192fc9",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- This notebook is an executable reference. In production, the adapter should be implemented under `level2/llm_adapter` and adapter outputs must be re-validated by the deterministic validators.\n",
    "- The functions here are intentionally conservative; they expose ambiguity rather than guessing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9244c0a3",
   "metadata": {},
   "source": [
    "# NSAI Level 1B: Multi-Detector Neuro-Symbolic Intent Classification\n",
    "\n",
    "**Architecture Shift:**\n",
    "- **Level 1A**: Single multi-class classifier\n",
    "- **Level 1B**: One binary detector per intent\n",
    "\n",
    "**Core Concept:**\n",
    "- Each detector independently scores: \"Does this match MY intent?\"\n",
    "- Scores ∈ [0,1], do NOT sum to 1\n",
    "- Rules (not models) decide final outcome\n",
    "\n",
    "**Dataset**: utterance, intent (4 classes: investigate, execution, summarization, out_of_scope)\n",
    "\n",
    "**Output**: Deterministic, explainable decisions with detector scores + rule governance\n",
    "\n",
    "**Method**: Multi-detector statistical learning + symbolic rule precedence (no LLMs, no timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf266dc0",
   "metadata": {},
   "source": [
    "## Part 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661554e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Import Level 1B module\n",
    "from level1b_model import Level1BClassifier, RULE_PRIORITY, RULE_TYPES, get_configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1a6ce8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "intent\n",
      "out_of_scope     169\n",
      "execution        150\n",
      "investigate      149\n",
      "summarization    146\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total: 614 records\n"
     ]
    }
   ],
   "source": [
    "# Load & Validate Data\n",
    "df = pd.read_csv('../data/intents_base.csv')\n",
    "\n",
    "# Assert columns\n",
    "assert set(df.columns) == {'utterance', 'intent'}, f\"Expected columns {{utterance, intent}}, got {set(df.columns)}\"\n",
    "\n",
    "# Normalize intent labels\n",
    "df['intent'] = df['intent'].str.lower().str.strip()\n",
    "\n",
    "# Show class distribution\n",
    "print(\"Class Distribution:\")\n",
    "print(df['intent'].value_counts())\n",
    "print(f\"\\nTotal: {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af02e28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 491 | Test: 123\n"
     ]
    }
   ],
   "source": [
    "# Train/Test Split\n",
    "X = df['utterance']\n",
    "y = df['intent']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)} | Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c603dac7",
   "metadata": {},
   "source": [
    "## Part 2: Multi-Detector Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb2edbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training binary detectors...\n",
      "\n",
      "         investigate detector: Accuracy=0.8130, F1=0.3784\n",
      "           execution detector: Accuracy=0.8211, F1=0.4211\n",
      "       summarization detector: Accuracy=0.9512, F1=0.8846\n",
      "        out_of_scope detector: Accuracy=0.8130, F1=0.4889\n",
      "\n",
      "All 4 detectors trained\n"
     ]
    }
   ],
   "source": [
    "# Intent-Specific Detector Models\n",
    "# Train ONE binary classifier per intent\n",
    "\n",
    "intents = ['investigate', 'execution', 'summarization', 'out_of_scope']\n",
    "detectors = {}\n",
    "\n",
    "print(\"Training binary detectors...\\n\")\n",
    "\n",
    "for intent in intents:\n",
    "    # Create binary labels: 1 if utterance matches this intent, 0 otherwise\n",
    "    y_binary_train = (y_train == intent).astype(int)\n",
    "    y_binary_test = (y_test == intent).astype(int)\n",
    "    \n",
    "    # Create detector pipeline\n",
    "    detector = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(\n",
    "            max_features=5000,\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words='english'\n",
    "        )),\n",
    "        ('classifier', LogisticRegression(\n",
    "            solver='lbfgs',\n",
    "            random_state=42,\n",
    "            max_iter=1000\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Train detector\n",
    "    detector.fit(X_train, y_binary_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = detector.predict(X_test)\n",
    "    report = classification_report(y_binary_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Store detector\n",
    "    detectors[intent] = detector\n",
    "    \n",
    "    print(f\"{intent:>20} detector: Accuracy={report['accuracy']:.4f}, F1={report['1']['f1-score']:.4f}\")\n",
    "\n",
    "print(f\"\\nAll {len(detectors)} detectors trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11669468",
   "metadata": {},
   "source": [
    "## Part 4: Level 1B Symbolic Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada31cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 1B Configuration:\n",
      "  BASE_MIN_SCORE: 0.5\n",
      "  AMBIGUITY_MARGIN: 0.1\n",
      "  EXECUTION_MIN_SCORE: 0.85\n",
      "  MIN_TOKENS_OUT_OF_SCOPE: 3\n",
      "  CONCURRENCE_THRESHOLD: 0.7\n",
      "\n",
      "Rule Priority: ['R_LOW_TOKEN_COUNT', 'R_NO_CONFIDENT_DETECTOR', 'R_EXEC_SAFETY', 'R_MULTI_DETECTOR_CONCURRENCE', 'R_AMBIGUOUS', 'R_DEFAULT']\n",
      "\n",
      "Rule Types:\n",
      "               R_LOW_TOKEN_COUNT → quality\n",
      "         R_NO_CONFIDENT_DETECTOR → quality\n",
      "                   R_EXEC_SAFETY → safety\n",
      "    R_MULTI_DETECTOR_CONCURRENCE → compound_intent\n",
      "                     R_AMBIGUOUS → ambiguity\n",
      "                       R_DEFAULT → default\n"
     ]
    }
   ],
   "source": [
    "# Level 1B Rule Configuration (from module)\n",
    "config = get_configuration()\n",
    "\n",
    "print(\"Level 1B Configuration:\")\n",
    "print(f\"  BASE_MIN_SCORE: {config['BASE_MIN_SCORE']}\")\n",
    "print(f\"  AMBIGUITY_MARGIN: {config['AMBIGUITY_MARGIN']}\")\n",
    "print(f\"  EXECUTION_MIN_SCORE: {config['EXECUTION_MIN_SCORE']}\")\n",
    "print(f\"  MIN_TOKENS_OUT_OF_SCOPE: {config['MIN_TOKENS_OUT_OF_SCOPE']}\")\n",
    "print(f\"  CONCURRENCE_THRESHOLD: {config['CONCURRENCE_THRESHOLD']}\")\n",
    "print(f\"\\nRule Priority: {config['RULE_PRIORITY']}\")\n",
    "print(f\"\\nRule Types:\")\n",
    "for rule, rtype in config['RULE_TYPES'].items():\n",
    "    print(f\"  {rule:>30} → {rtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e5e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 1B symbolic rules defined\n",
      "✓ Gap 1 fixed: Explicit R_NO_CONFIDENT_DETECTOR rule\n",
      "✓ Gap 2 fixed: All rules tagged with rule_type\n",
      "✓ Gap 3 fixed: R_MULTI_DETECTOR_CONCURRENCE reserved for L2\n"
     ]
    }
   ],
   "source": [
    "# Initialize Level 1B Classifier with trained detectors\n",
    "classifier = Level1BClassifier(detectors=detectors, intents=intents)\n",
    "\n",
    "print(\"Level 1B classifier initialized with multi-detector architecture\")\n",
    "print(\"✓ Gap 1 fixed: Explicit R_NO_CONFIDENT_DETECTOR rule\")\n",
    "print(\"✓ Gap 2 fixed: All rules tagged with rule_type\")\n",
    "print(\"✓ Gap 3 fixed: R_MULTI_DETECTOR_CONCURRENCE reserved for L2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f90692",
   "metadata": {},
   "source": [
    "## Part 6: Explainable Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ee074b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "LEVEL 1B: MULTI-DETECTOR NEURO-SYMBOLIC INFERENCE\n",
      "====================================================================================================\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "UTTERANCE: why is server cpu high\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "DETECTOR SCORES:\n",
      "           investigate: 0.4892 ████████████████████████\n",
      "             execution: 0.2212 ███████████\n",
      "          out_of_scope: 0.1736 ████████\n",
      "         summarization: 0.1229 ██████\n",
      "\n",
      "  Top Detector: investigate\n",
      "  Score Margin: 0.2681\n",
      "  Meaningful Tokens: 4\n",
      "\n",
      "TRIGGERED RULES:\n",
      "  [ 95] R_NO_CONFIDENT_DETECTOR        (type: quality)\n",
      "       Condition: all detector_scores < 0.5\n",
      "       Signal Value: 0.4892277767198669\n",
      "       → No detector confident enough to classify\n",
      "\n",
      "FINAL DECISION:\n",
      "  Predicted Intent: out_of_scope\n",
      "  Decision State: blocked\n",
      "  Decision Reason: R_NO_CONFIDENT_DETECTOR\n",
      "\n",
      "STRUCTURED OUTPUT:\n",
      "{\n",
      "  \"utterance\": \"why is server cpu high\",\n",
      "  \"predicted_intent\": \"out_of_scope\",\n",
      "  \"decision_state\": \"blocked\",\n",
      "  \"decision_reason\": \"R_NO_CONFIDENT_DETECTOR\",\n",
      "  \"detector_scores\": {\n",
      "    \"investigate\": 0.4892277767198669,\n",
      "    \"execution\": 0.2211607689562297,\n",
      "    \"summarization\": 0.12286171348553303,\n",
      "    \"out_of_scope\": 0.1736435468802665\n",
      "  },\n",
      "  \"score_margin\": 0.26806700776363723,\n",
      "  \"meaningful_tokens\": 4\n",
      "}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "UTTERANCE: restart nginx on host123\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "DETECTOR SCORES:\n",
      "             execution: 0.5114 █████████████████████████\n",
      "          out_of_scope: 0.1952 █████████\n",
      "           investigate: 0.1748 ████████\n",
      "         summarization: 0.1272 ██████\n",
      "\n",
      "  Top Detector: execution\n",
      "  Score Margin: 0.3161\n",
      "  Meaningful Tokens: 5\n",
      "\n",
      "TRIGGERED RULES:\n",
      "  [ 90] R_EXEC_SAFETY                  (type: safety)\n",
      "       Condition: execution_score >= 0.5 AND < 0.85\n",
      "       Signal Value: 0.5113605996601521\n",
      "\n",
      "FINAL DECISION:\n",
      "  Predicted Intent: execution\n",
      "  Decision State: needs_clarification\n",
      "  Decision Reason: R_EXEC_SAFETY\n",
      "\n",
      "STRUCTURED OUTPUT:\n",
      "{\n",
      "  \"utterance\": \"restart nginx on host123\",\n",
      "  \"predicted_intent\": \"execution\",\n",
      "  \"decision_state\": \"needs_clarification\",\n",
      "  \"decision_reason\": \"R_EXEC_SAFETY\",\n",
      "  \"detector_scores\": {\n",
      "    \"investigate\": 0.174777754729613,\n",
      "    \"execution\": 0.5113605996601521,\n",
      "    \"summarization\": 0.12724423992407163,\n",
      "    \"out_of_scope\": 0.1952228071753816\n",
      "  },\n",
      "  \"score_margin\": 0.31613779248477053,\n",
      "  \"meaningful_tokens\": 5\n",
      "}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "UTTERANCE: summarize the incident from yesterday\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "DETECTOR SCORES:\n",
      "         summarization: 0.6900 ██████████████████████████████████\n",
      "          out_of_scope: 0.1459 ███████\n",
      "             execution: 0.1202 ██████\n",
      "           investigate: 0.1188 █████\n",
      "\n",
      "  Top Detector: summarization\n",
      "  Score Margin: 0.5441\n",
      "  Meaningful Tokens: 4\n",
      "\n",
      "TRIGGERED RULES:\n",
      "  [ 10] R_DEFAULT                      (type: default)\n",
      "       Condition: default to highest scoring detector\n",
      "       Signal Value: 0.6899742575973363\n",
      "\n",
      "FINAL DECISION:\n",
      "  Predicted Intent: summarization\n",
      "  Decision State: accepted\n",
      "  Decision Reason: R_DEFAULT\n",
      "\n",
      "STRUCTURED OUTPUT:\n",
      "{\n",
      "  \"utterance\": \"summarize the incident from yesterday\",\n",
      "  \"predicted_intent\": \"summarization\",\n",
      "  \"decision_state\": \"accepted\",\n",
      "  \"decision_reason\": \"R_DEFAULT\",\n",
      "  \"detector_scores\": {\n",
      "    \"investigate\": 0.11877405147715141,\n",
      "    \"execution\": 0.1202339598623489,\n",
      "    \"summarization\": 0.6899742575973363,\n",
      "    \"out_of_scope\": 0.14590218255954812\n",
      "  },\n",
      "  \"score_margin\": 0.5440720750377882,\n",
      "  \"meaningful_tokens\": 4\n",
      "}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "UTTERANCE: hello\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "DETECTOR SCORES:\n",
      "          out_of_scope: 0.4243 █████████████████████\n",
      "             execution: 0.2015 ██████████\n",
      "           investigate: 0.1957 █████████\n",
      "         summarization: 0.1553 ███████\n",
      "\n",
      "  Top Detector: out_of_scope\n",
      "  Score Margin: 0.2228\n",
      "  Meaningful Tokens: 1\n",
      "\n",
      "TRIGGERED RULES:\n",
      "  [100] R_LOW_TOKEN_COUNT              (type: quality)\n",
      "       Condition: meaningful_tokens < 3\n",
      "       Signal Value: 1\n",
      "\n",
      "FINAL DECISION:\n",
      "  Predicted Intent: out_of_scope\n",
      "  Decision State: blocked\n",
      "  Decision Reason: R_LOW_TOKEN_COUNT\n",
      "\n",
      "STRUCTURED OUTPUT:\n",
      "{\n",
      "  \"utterance\": \"hello\",\n",
      "  \"predicted_intent\": \"out_of_scope\",\n",
      "  \"decision_state\": \"blocked\",\n",
      "  \"decision_reason\": \"R_LOW_TOKEN_COUNT\",\n",
      "  \"detector_scores\": {\n",
      "    \"investigate\": 0.19572183320937875,\n",
      "    \"execution\": 0.20152796178402685,\n",
      "    \"summarization\": 0.15528711455888855,\n",
      "    \"out_of_scope\": 0.4243448663251203\n",
      "  },\n",
      "  \"score_margin\": 0.22281690454109346,\n",
      "  \"meaningful_tokens\": 1\n",
      "}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "UTTERANCE: delete all production databases\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "DETECTOR SCORES:\n",
      "          out_of_scope: 0.2658 █████████████\n",
      "             execution: 0.2643 █████████████\n",
      "           investigate: 0.2453 ████████████\n",
      "         summarization: 0.1617 ████████\n",
      "\n",
      "  Top Detector: out_of_scope\n",
      "  Score Margin: 0.0015\n",
      "  Meaningful Tokens: 1\n",
      "\n",
      "TRIGGERED RULES:\n",
      "  [100] R_LOW_TOKEN_COUNT              (type: quality)\n",
      "       Condition: meaningful_tokens < 3\n",
      "       Signal Value: 1\n",
      "\n",
      "FINAL DECISION:\n",
      "  Predicted Intent: out_of_scope\n",
      "  Decision State: blocked\n",
      "  Decision Reason: R_LOW_TOKEN_COUNT\n",
      "\n",
      "STRUCTURED OUTPUT:\n",
      "{\n",
      "  \"utterance\": \"delete all production databases\",\n",
      "  \"predicted_intent\": \"out_of_scope\",\n",
      "  \"decision_state\": \"blocked\",\n",
      "  \"decision_reason\": \"R_LOW_TOKEN_COUNT\",\n",
      "  \"detector_scores\": {\n",
      "    \"investigate\": 0.2452523844517869,\n",
      "    \"execution\": 0.26428996752003386,\n",
      "    \"summarization\": 0.16167044351324839,\n",
      "    \"out_of_scope\": 0.26582573859164355\n",
      "  },\n",
      "  \"score_margin\": 0.0015357710716096817,\n",
      "  \"meaningful_tokens\": 1\n",
      "}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "UTTERANCE: server issues yesterday\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "DETECTOR SCORES:\n",
      "           investigate: 0.2970 ██████████████\n",
      "             execution: 0.2513 ████████████\n",
      "          out_of_scope: 0.2209 ███████████\n",
      "         summarization: 0.1681 ████████\n",
      "\n",
      "  Top Detector: investigate\n",
      "  Score Margin: 0.0458\n",
      "  Meaningful Tokens: 3\n",
      "\n",
      "TRIGGERED RULES:\n",
      "  [ 95] R_NO_CONFIDENT_DETECTOR        (type: quality)\n",
      "       Condition: all detector_scores < 0.5\n",
      "       Signal Value: 0.2970289285541023\n",
      "       → No detector confident enough to classify\n",
      "\n",
      "FINAL DECISION:\n",
      "  Predicted Intent: out_of_scope\n",
      "  Decision State: blocked\n",
      "  Decision Reason: R_NO_CONFIDENT_DETECTOR\n",
      "\n",
      "STRUCTURED OUTPUT:\n",
      "{\n",
      "  \"utterance\": \"server issues yesterday\",\n",
      "  \"predicted_intent\": \"out_of_scope\",\n",
      "  \"decision_state\": \"blocked\",\n",
      "  \"decision_reason\": \"R_NO_CONFIDENT_DETECTOR\",\n",
      "  \"detector_scores\": {\n",
      "    \"investigate\": 0.2970289285541023,\n",
      "    \"execution\": 0.25126757307307507,\n",
      "    \"summarization\": 0.1681449870794448,\n",
      "    \"out_of_scope\": 0.22086979607395582\n",
      "  },\n",
      "  \"score_margin\": 0.04576135548102722,\n",
      "  \"meaningful_tokens\": 3\n",
      "}\n",
      "\n",
      "====================================================================================================\n",
      "DEMO COMPLETE\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Explainable Demo Output\n",
    "test_utterances = [\n",
    "    \"why is server cpu high\",\n",
    "    \"restart nginx on host123\",\n",
    "    \"summarize the incident from yesterday\",\n",
    "    \"hello\",\n",
    "    \"delete all production databases\",\n",
    "    \"server issues yesterday\"\n",
    "]\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"LEVEL 1B: MULTI-DETECTOR NEURO-SYMBOLIC INFERENCE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for utterance in test_utterances:\n",
    "    result = classifier.predict(utterance)\n",
    "    \n",
    "    print(f\"\\n{'-'*100}\")\n",
    "    print(f\"UTTERANCE: {utterance}\")\n",
    "    print(f\"{'-'*100}\")\n",
    "    \n",
    "    # Detector scores\n",
    "    print(f\"\\nDETECTOR SCORES:\")\n",
    "    for intent, score in sorted(result['detector_scores'].items(), key=lambda x: x[1], reverse=True):\n",
    "        bar = '█' * int(score * 50)\n",
    "        print(f\"  {intent:>20}: {score:.4f} {bar}\")\n",
    "    \n",
    "    print(f\"\\n  Top Detector: {result['top_detector']}\")\n",
    "    print(f\"  Score Margin: {result['score_margin']:.4f}\")\n",
    "    print(f\"  Meaningful Tokens: {result['meaningful_tokens']}\")\n",
    "    \n",
    "    # Triggered rules with rule_type\n",
    "    print(f\"\\nTRIGGERED RULES:\")\n",
    "    for rule in sorted(result['triggered_rules'], key=lambda r: r['priority'], reverse=True):\n",
    "        rule_type = rule.get('rule_type', 'unknown')\n",
    "        print(f\"  [{rule['priority']:3d}] {rule['rule_id']:30s} (type: {rule_type})\")\n",
    "        print(f\"       Condition: {rule['condition']}\")\n",
    "        print(f\"       Signal Value: {rule['value']}\")\n",
    "        if 'explanation' in rule:\n",
    "            print(f\"       → {rule['explanation']}\")\n",
    "    \n",
    "    # Final decision\n",
    "    print(f\"\\nFINAL DECISION:\")\n",
    "    print(f\"  Predicted Intent: {result['predicted_intent']}\")\n",
    "    print(f\"  Decision State: {result['decision_state']}\")\n",
    "    print(f\"  Decision Reason: {result['decision_reason']}\")\n",
    "    \n",
    "    # Structured JSON\n",
    "    print(f\"\\nSTRUCTURED OUTPUT:\")\n",
    "    output_json = {\n",
    "        'utterance': utterance,\n",
    "        'predicted_intent': result['predicted_intent'],\n",
    "        'decision_state': result['decision_state'],\n",
    "        'decision_reason': result['decision_reason'],\n",
    "        'detector_scores': result['detector_scores'],\n",
    "        'score_margin': result['score_margin'],\n",
    "        'meaningful_tokens': result['meaningful_tokens']\n",
    "    }\n",
    "    print(json.dumps(output_json, indent=2))\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"DEMO COMPLETE\")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3d8045",
   "metadata": {},
   "source": [
    "## Validation: Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c80fd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Level 1B on test set...\n",
      "\n",
      "Accuracy: 0.4878\n",
      "\n",
      "Decision State Distribution:\n",
      "               blocked:  97 (78.9%)\n",
      "              accepted:  22 (17.9%)\n",
      "   needs_clarification:   4 (3.3%)\n",
      "\n",
      "Rule Trigger Counts:\n",
      "     R_LOW_TOKEN_COUNT:  52 (42.3%)\n",
      "  R_NO_CONFIDENT_DETECTOR:  45 (36.6%)\n",
      "         R_EXEC_SAFETY:   4 (3.3%)\n",
      "  R_MULTI_DETECTOR_CONCURRENCE:   0 (0.0%)\n",
      "           R_AMBIGUOUS:   0 (0.0%)\n",
      "             R_DEFAULT:  22 (17.9%)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    execution       1.00      0.13      0.24        30\n",
      "  investigate       1.00      0.17      0.29        30\n",
      " out_of_scope       0.35      1.00      0.52        34\n",
      "summarization       1.00      0.59      0.74        29\n",
      "\n",
      "     accuracy                           0.49       123\n",
      "    macro avg       0.84      0.47      0.44       123\n",
      " weighted avg       0.82      0.49      0.44       123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Level 1B on test set\n",
    "print(\"Evaluating Level 1B on test set...\\n\")\n",
    "\n",
    "predictions = []\n",
    "decision_states = []\n",
    "rule_counts = {rule: 0 for rule in RULE_PRIORITY}\n",
    "\n",
    "for text, true_intent in zip(X_test, y_test):\n",
    "    result = classifier.predict(text)\n",
    "    predictions.append(result['predicted_intent'])\n",
    "    decision_states.append(result['decision_state'])\n",
    "    \n",
    "    # Count triggered rules\n",
    "    for rule in result['triggered_rules']:\n",
    "        rule_counts[rule['rule_id']] += 1\n",
    "\n",
    "# Accuracy\n",
    "accuracy = sum(p == t for p, t in zip(predictions, y_test)) / len(y_test)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Decision state distribution\n",
    "print(f\"\\nDecision State Distribution:\")\n",
    "from collections import Counter\n",
    "state_counts = Counter(decision_states)\n",
    "for state, count in state_counts.items():\n",
    "    print(f\"  {state:>20}: {count:3d} ({count/len(decision_states)*100:.1f}%)\")\n",
    "\n",
    "# Rule trigger counts\n",
    "print(f\"\\nRule Trigger Counts:\")\n",
    "for rule in RULE_PRIORITY:\n",
    "    count = rule_counts[rule]\n",
    "    print(f\"  {rule:>20}: {count:3d} ({count/len(X_test)*100:.1f}%)\")\n",
    "\n",
    "# Full classification report\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d64e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving detailed predictions...\n",
      "✓ Saved predictions: artifacts/level1b/level1b_predictions.csv\n",
      "✓ Saved JSONL: artifacts/level1b/level1b_predictions.jsonl\n",
      "\n",
      "Saving evaluation metrics...\n",
      "✓ Saved metrics: artifacts/level1b/evaluation_metrics.json\n",
      "\n",
      "Saving rule activation analysis...\n",
      "✓ Saved rule stats: artifacts/level1b/rule_activation_stats.csv\n",
      "\n",
      "Saving decision state breakdown...\n",
      "✓ Saved state breakdown: artifacts/level1b/decision_state_breakdown.csv\n",
      "\n",
      "================================================================================\n",
      "All Level 1B artifacts saved to: artifacts/level1b/\n",
      "================================================================================\n",
      "Files created:\n",
      "  - level1b_predictions.csv (detailed predictions)\n",
      "  - level1b_predictions.jsonl (for debugging)\n",
      "  - evaluation_metrics.json (comprehensive metrics)\n",
      "  - rule_activation_stats.csv (rule analysis)\n",
      "  - decision_state_breakdown.csv (state distribution)\n"
     ]
    }
   ],
   "source": [
    "# Save Level 1B Results to Artifacts\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create artifacts directory\n",
    "artifacts_dir = 'artifacts/level1b'\n",
    "os.makedirs(artifacts_dir, exist_ok=True)\n",
    "\n",
    "# 1. Save the trained model\n",
    "print(\"Saving trained model...\")\n",
    "model_dir = 'models/level1b'\n",
    "classifier.save(model_dir)\n",
    "\n",
    "# 2. Save detailed predictions with all metadata\n",
    "print(\"\\nSaving detailed predictions...\")\n",
    "detailed_results = []\n",
    "\n",
    "for i, (text, true_intent) in enumerate(zip(X_test, y_test)):\n",
    "    result = classifier.predict(text)\n",
    "    \n",
    "    detailed_results.append({\n",
    "        'test_index': i,\n",
    "        'utterance': text,\n",
    "        'true_intent': true_intent,\n",
    "        'predicted_intent': result['predicted_intent'],\n",
    "        'decision_state': result['decision_state'],\n",
    "        'decision_reason': result['decision_reason'],\n",
    "        'top_detector': result['top_detector'],\n",
    "        'score_margin': result['score_margin'],\n",
    "        'meaningful_tokens': result['meaningful_tokens'],\n",
    "        **{f'score_{intent}': result['detector_scores'][intent] for intent in intents},\n",
    "        'triggered_rules': [r['rule_id'] for r in result['triggered_rules']],\n",
    "        'primary_rule_type': result['triggered_rules'][-1].get('rule_type', 'unknown') if result['triggered_rules'] else 'none'\n",
    "    })\n",
    "\n",
    "# Save as CSV\n",
    "df_results = pd.DataFrame(detailed_results)\n",
    "csv_path = f\"{artifacts_dir}/level1b_predictions.csv\"\n",
    "df_results.to_csv(csv_path, index=False)\n",
    "print(f\"✓ Saved predictions: {csv_path}\")\n",
    "\n",
    "# Save as JSONL for debugging\n",
    "jsonl_path = f\"{artifacts_dir}/level1b_predictions.jsonl\"\n",
    "with open(jsonl_path, 'w') as f:\n",
    "    for result in detailed_results:\n",
    "        f.write(json.dumps(result) + '\\n')\n",
    "print(f\"✓ Saved JSONL: {jsonl_path}\")\n",
    "\n",
    "# 3. Save evaluation metrics\n",
    "print(\"\\nSaving evaluation metrics...\")\n",
    "config = get_configuration()\n",
    "eval_metrics = {\n",
    "    'model': 'level1b_multi_detector',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'test_size': len(X_test),\n",
    "    'accuracy': accuracy,\n",
    "    'decision_state_distribution': dict(state_counts),\n",
    "    'rule_trigger_counts': rule_counts,\n",
    "    'rule_trigger_percentages': {rule: count/len(X_test)*100 for rule, count in rule_counts.items()},\n",
    "    'classification_report': classification_report(y_test, predictions, output_dict=True),\n",
    "    'configuration': config\n",
    "}\n",
    "\n",
    "metrics_path = f\"{artifacts_dir}/evaluation_metrics.json\"\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(eval_metrics, f, indent=2)\n",
    "print(f\"✓ Saved metrics: {metrics_path}\")\n",
    "\n",
    "# 4. Save rule activation analysis\n",
    "print(\"\\nSaving rule activation analysis...\")\n",
    "rule_analysis = []\n",
    "for rule in RULE_PRIORITY:\n",
    "    rule_results = [r for r in detailed_results if rule in r['triggered_rules']]\n",
    "    \n",
    "    rule_analysis.append({\n",
    "        'rule_id': rule,\n",
    "        'rule_type': RULE_TYPES.get(rule, 'unknown'),\n",
    "        'trigger_count': rule_counts[rule],\n",
    "        'trigger_percentage': rule_counts[rule]/len(X_test)*100,\n",
    "        'decision_states': dict(Counter([r['decision_state'] for r in rule_results]))\n",
    "    })\n",
    "\n",
    "df_rules = pd.DataFrame(rule_analysis)\n",
    "rules_path = f\"{artifacts_dir}/rule_activation_stats.csv\"\n",
    "df_rules.to_csv(rules_path, index=False)\n",
    "print(f\"✓ Saved rule stats: {rules_path}\")\n",
    "\n",
    "# 5. Save decision state breakdown by intent\n",
    "print(\"\\nSaving decision state breakdown...\")\n",
    "state_breakdown = []\n",
    "for intent in intents:\n",
    "    intent_predictions = [r for r in detailed_results if r['predicted_intent'] == intent]\n",
    "    \n",
    "    state_breakdown.append({\n",
    "        'predicted_intent': intent,\n",
    "        'total_predictions': len(intent_predictions),\n",
    "        'accepted': sum(1 for r in intent_predictions if r['decision_state'] == 'accepted'),\n",
    "        'needs_clarification': sum(1 for r in intent_predictions if r['decision_state'] == 'needs_clarification'),\n",
    "        'blocked': sum(1 for r in intent_predictions if r['decision_state'] == 'blocked'),\n",
    "        'avg_score_margin': np.mean([r['score_margin'] for r in intent_predictions]) if intent_predictions else 0\n",
    "    })\n",
    "\n",
    "df_states = pd.DataFrame(state_breakdown)\n",
    "states_path = f\"{artifacts_dir}/decision_state_breakdown.csv\"\n",
    "df_states.to_csv(states_path, index=False)\n",
    "print(f\"✓ Saved state breakdown: {states_path}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"All Level 1B artifacts saved\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Model: {model_dir}/\")\n",
    "print(f\"Artifacts: {artifacts_dir}/\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  - level1b_predictions.csv (detailed predictions)\")\n",
    "print(f\"  - level1b_predictions.jsonl (for debugging)\")\n",
    "print(f\"  - evaluation_metrics.json (comprehensive metrics)\")\n",
    "print(f\"  - rule_activation_stats.csv (rule analysis)\")\n",
    "print(f\"  - decision_state_breakdown.csv (state distribution)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

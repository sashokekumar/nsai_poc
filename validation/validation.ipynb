{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8946cda3",
   "metadata": {},
   "source": [
    "# NSAI Model Validation: Level 0 vs Level 1A vs Level 1B\n",
    "\n",
    "**Purpose**: Compare all three architectural approaches on unseen test data\n",
    "\n",
    "**Models**:\n",
    "- **Level 0**: Baseline TF-IDF + Logistic Regression (confidence thresholding)\n",
    "- **Level 1A**: Single multi-class classifier + symbolic rules\n",
    "- **Level 1B**: Multi-detector architecture + explicit rule types\n",
    "\n",
    "**Test Data**: `test_data.csv` (20 examples, 5 per intent, NOT in training set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4174d22",
   "metadata": {},
   "source": [
    "## Part 1: Load All Three Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e25d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Add workspace-relative paths for modules (robustly find repo root)\n",
    "def find_repo_root(start_dir=None):\n",
    "    d = start_dir or os.getcwd()\n",
    "    while True:\n",
    "        if os.path.exists(os.path.join(d, 'requirements.txt')) or os.path.exists(os.path.join(d, '.git')):\n",
    "            return d\n",
    "        parent = os.path.dirname(d)\n",
    "        if parent == d:\n",
    "            return os.getcwd()\n",
    "        d = parent\n",
    "repo_root = find_repo_root()\n",
    "# Add repository root so top-level packages like 'level0' and 'level1' import correctly\n",
    "sys.path.insert(0, repo_root)\n",
    "\n",
    "from level0.level0_model import Level0Classifier\n",
    "from level1.level1b_model import Level1BClassifier\n",
    "# Import Level1 utilities (pipeline + rule functions) for fallback training\n",
    "from level1.level1_model import create_level1_pipeline, extract_signals, apply_decision_rules\n",
    "\n",
    "# Import Level2 deterministic pipeline pieces\n",
    "from level2 import clause_extractor, normalizer, validator\n",
    "try:\n",
    "    from level2.llm_adapter import adapter as llm_adapter\n",
    "except Exception:\n",
    "    llm_adapter = None\n",
    "\n",
    "# Lightweight L2 pipeline helper used only for validation reporting\n",
    "def l2_pipeline(utterance: str, intent: str, use_adapter: bool = False) -> dict:\n",
    "    adapter_result = {}\n",
    "    if use_adapter and llm_adapter is not None:\n",
    "        adapter_result = llm_adapter.extract_clauses(utterance) or {}\n",
    "    clauses, detectors = clause_extractor.extract_candidates(utterance, use_adapter=use_adapter, adapter_result=adapter_result)\n",
    "    normalized = normalizer.normalize_clauses(clauses)\n",
    "    decision_state, details, ambiguity = validator.validate(normalized, intent)\n",
    "    decision_trace = {\n",
    "        'detectors_fired': detectors,\n",
    "        'hard_rules_failed': details.get('hard_rules_failed', []),\n",
    "        'soft_rules_passed': details.get('soft_rules_passed', []),\n",
    "        'alternatives_eliminated': {},\n",
    "    }\n",
    "    return {\n",
    "        'clauses': normalized,\n",
    "        'decision_state': decision_state,\n",
    "        'ambiguity': ambiguity,\n",
    "        'decision_trace': decision_trace,\n",
    "        'metadata': {'adapter_used': bool(use_adapter)},\n",
    "    }\n",
    "\n",
    "print('✓ Imports successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89f3bdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded Level 0 model from ..\\level0\\models\n",
      "✓ Loaded Level 1B model from ..\\level1\\models\\level1b\n",
      "  Detectors: ['investigate', 'execution', 'summarization', 'out_of_scope']\n",
      "Level1A model not found; training a local Level1A pipeline fallback (on full dataset)\n",
      "✓ Level1A fallback pipeline trained\n",
      "\n",
      "✓ All models ready (Level0, Level1A, Level1B)\n"
     ]
    }
   ],
   "source": [
    "# Load Level 0 and Level 1B models; provide Level 1A fallback if model missing\n",
    "level0 = Level0Classifier.load('../level0/models')\n",
    "\n",
    "# Level 1B (multi-detector) - load from saved detectors\n",
    "level1b = Level1BClassifier.load('../level1/models/level1b')\n",
    "\n",
    "# Level 1A (multi-class) - try to load saved model, otherwise train a local pipeline fallback\n",
    "level1a_model_dir = '../level1/models/level1a'\n",
    "level1a = None\n",
    "\n",
    "if os.path.isdir(level1a_model_dir):\n",
    "    try:\n",
    "        # If there's a saved Level1Classifier class, attempt to load it\n",
    "        from level1.level1_model import Level1Classifier\n",
    "        level1a = Level1Classifier.load(level1a_model_dir)\n",
    "        print('✓ Loaded Level1A from models')\n",
    "    except Exception:\n",
    "        level1a = None\n",
    "\n",
    "if level1a is None:\n",
    "    print('Level1A model not found; training a local Level1A pipeline fallback (on full dataset)')\n",
    "    # Train a quick Level1 pipeline using the shared dataset\n",
    "    df_all = pd.read_csv('../data/intents_base.csv')\n",
    "    df_all['intent'] = df_all['intent'].str.lower().str.strip()\n",
    "    X_all = df_all['utterance']\n",
    "    y_all = df_all['intent']\n",
    "\n",
    "    level1_pipeline = create_level1_pipeline()\n",
    "    level1_pipeline.fit(X_all, y_all)\n",
    "\n",
    "    # Wrapper to provide .predict(text) interface matching notebook expectations\n",
    "    class Level1AWrapper:\n",
    "        def __init__(self, pipeline):\n",
    "            self.pipeline = pipeline\n",
    "        def predict(self, text):\n",
    "            signals = extract_signals(text, self.pipeline)\n",
    "            rules_out = apply_decision_rules(signals)\n",
    "            return {\n",
    "                'predicted_intent': rules_out['predicted_intent'],\n",
    "                'decision_state': rules_out['decision_state'],\n",
    "                'decision_reason': rules_out['decision_reason'],\n",
    "                'max_confidence': signals['max_confidence'],\n",
    "                'margin': signals['margin'],\n",
    "                'meaningful_tokens': signals['meaningful_tokens'],\n",
    "                'probabilities': signals['probabilities'],\n",
    "                'triggered_rules': rules_out['triggered_rules']\n",
    "            }\n",
    "\n",
    "    level1a = Level1AWrapper(level1_pipeline)\n",
    "    print('✓ Level1A fallback pipeline trained')\n",
    "\n",
    "print('\\n✓ All models ready (Level0, Level1A, Level1B)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181784ff",
   "metadata": {},
   "source": [
    "## Part 2: Load Test Data (Not in Training Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c868b2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data loaded: 20 examples\n",
      "\n",
      "Sample data:\n",
      "                                           utterance\n",
      "0    what's causing the spike in CPU usage on web-01\n",
      "1  can you check why memory is so high on prod se...\n",
      "2  find out what made the service crash this morning\n",
      "3           look into the sudden increase in latency\n",
      "4    diagnose why the app is running slow on staging\n",
      "5                         reboot the web server farm\n",
      "6              scale our API tier up to 10 instances\n",
      "7           terminate the frozen process on worker-5\n",
      "8                  push the hotfix to production now\n",
      "9          clean up old logs from all database nodes\n"
     ]
    }
   ],
   "source": [
    "# Load test data (utterance only)\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "print(f'Test data loaded: {len(test_df)} examples')\n",
    "print(f\"\\nSample data:\")\n",
    "print(test_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d187f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Predictions complete: 20 examples\n"
     ]
    }
   ],
   "source": [
    "# Run predictions from all three models\n",
    "results = []\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    utterance = row['utterance']\n",
    "    \n",
    "    # Level 0\n",
    "    l0_result = level0.predict(utterance, return_probabilities=True)\n",
    "    \n",
    "    # Level 1A  \n",
    "    l1a_result = level1a.predict(utterance)\n",
    "    \n",
    "    # Level 1B\n",
    "    l1b_result = level1b.predict(utterance)\n",
    "    \n",
    "    # Level 2 (deterministic pipeline) - use L1B intent as context when available\n",
    "    try:\n",
    "        l2_intent = l1b_result.get('predicted_intent') or l0_result.get('intent')\n",
    "    except Exception:\n",
    "        l2_intent = l0_result.get('intent')\n",
    "    l2_result = l2_pipeline(utterance, intent=l2_intent, use_adapter=False)\n",
    "    \n",
    "    # Compile results\n",
    "    results.append({\n",
    "        'utterance': utterance,\n",
    "        \n",
    "        # Level 0\n",
    "        'l0_intent': l0_result['intent'],\n",
    "        'l0_confidence': l0_result['confidence'],\n",
    "        'l0_abstained': l0_result['abstained'],\n",
    "        \n",
    "        # Level 1A\n",
    "        'l1a_intent': l1a_result['predicted_intent'],\n",
    "        'l1a_decision_state': l1a_result['decision_state'],\n",
    "        'l1a_decision_reason': l1a_result['decision_reason'],\n",
    "        'l1a_confidence': l1a_result['max_confidence'],\n",
    "        \n",
    "        # Level 1B\n",
    "        'l1b_intent': l1b_result['predicted_intent'],\n",
    "        'l1b_decision_state': l1b_result['decision_state'],\n",
    "        'l1b_decision_reason': l1b_result['decision_reason'],\n",
    "        'l1b_top_score': l1b_result['detector_scores'][l1b_result['top_detector']],\n",
    "        'l1b_score_margin': l1b_result['score_margin'],\n",
    "        'l1b_decision_trace': json.dumps(l1b_result.get('decision_trace', {})),\n",
    "        \n",
    "        # Level 2\n",
    "        'l2_decision_state': l2_result.get('decision_state'),\n",
    "        'l2_first_pass': 'success' if l2_result.get('decision_state') == 'accepted' else ('partial' if l2_result.get('decision_state') == 'needs_clarification' else 'failure'),\n",
    "        'l2_ambiguity': json.dumps(l2_result.get('ambiguity', {})),\n",
    "        'l2_clauses': json.dumps(l2_result.get('clauses', {})),\n",
    "        'l2_decision_trace': json.dumps(l2_result.get('decision_trace', {}))\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f'✓ Predictions complete: {len(results_df)} examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3b09ac",
   "metadata": {},
   "source": [
    "## Part 3: Run All Models & Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4eea1102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "COMPREHENSIVE 3-MODEL COMPARISON (NO GROUND TRUTH)\n",
      "============================================================================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[1] what's causing the spike in CPU usage on web-01\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : investigate     | conf=0.789\n",
      "LEVEL 1A: investigate     | conf=0.608 [accepted] (model_prediction)\n",
      "LEVEL 1B: investigate     | score=0.516, margin=0.327 [accepted] (R_DEFAULT)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[2] can you check why memory is so high on prod server\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : investigate     | conf=0.815\n",
      "LEVEL 1A: investigate     | conf=0.757 [accepted] (model_prediction)\n",
      "LEVEL 1B: investigate     | score=0.660, margin=0.484 [accepted] (R_DEFAULT)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[3] find out what made the service crash this morning\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.306 (ABSTAINED)\n",
      "LEVEL 1A: investigate     | conf=0.295 [blocked] (insufficient_tokens)\n",
      "LEVEL 1B: out_of_scope    | score=0.264, margin=0.020 [blocked] (R_LOW_TOKEN_COUNT)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[4] look into the sudden increase in latency\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.699 (ABSTAINED)\n",
      "LEVEL 1A: investigate     | conf=0.517 [needs_clarification] (ambiguous_prediction)\n",
      "LEVEL 1B: out_of_scope    | score=0.400, margin=0.194 [blocked] (R_NO_CONFIDENT_DETECTOR)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[5] diagnose why the app is running slow on staging\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.362 (ABSTAINED)\n",
      "LEVEL 1A: execution       | conf=0.314 [needs_clarification] (execution_low_confidence)\n",
      "LEVEL 1B: out_of_scope    | score=0.282, margin=0.021 [blocked] (R_NO_CONFIDENT_DETECTOR)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[6] reboot the web server farm\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.509 (ABSTAINED)\n",
      "LEVEL 1A: execution       | conf=0.399 [needs_clarification] (execution_low_confidence)\n",
      "LEVEL 1B: out_of_scope    | score=0.328, margin=0.071 [blocked] (R_NO_CONFIDENT_DETECTOR)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[7] scale our API tier up to 10 instances\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.659 (ABSTAINED)\n",
      "LEVEL 1A: execution       | conf=0.537 [needs_clarification] (execution_low_confidence)\n",
      "LEVEL 1B: out_of_scope    | score=0.417, margin=0.211 [blocked] (R_NO_CONFIDENT_DETECTOR)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[8] terminate the frozen process on worker-5\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.478 (ABSTAINED)\n",
      "LEVEL 1A: execution       | conf=0.325 [needs_clarification] (execution_low_confidence)\n",
      "LEVEL 1B: out_of_scope    | score=0.310, margin=0.067 [blocked] (R_LOW_TOKEN_COUNT)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[9] push the hotfix to production now\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.381 (ABSTAINED)\n",
      "LEVEL 1A: execution       | conf=0.351 [needs_clarification] (execution_low_confidence)\n",
      "LEVEL 1B: out_of_scope    | score=0.307, margin=0.021 [blocked] (R_NO_CONFIDENT_DETECTOR)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[10] clean up old logs from all database nodes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.546 (ABSTAINED)\n",
      "LEVEL 1A: execution       | conf=0.519 [needs_clarification] (execution_low_confidence)\n",
      "LEVEL 1B: out_of_scope    | score=0.411, margin=0.161 [blocked] (R_NO_CONFIDENT_DETECTOR)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[11] recap what happened during last night's downtime\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.570 (ABSTAINED)\n",
      "LEVEL 1A: summarization   | conf=0.360 [blocked] (insufficient_tokens)\n",
      "LEVEL 1B: out_of_scope    | score=0.314, margin=0.037 [blocked] (R_LOW_TOKEN_COUNT)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[12] give me an overview of this week's critical alerts\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : summarization   | conf=0.719\n",
      "LEVEL 1A: summarization   | conf=0.487 [needs_clarification] (ambiguous_prediction)\n",
      "LEVEL 1B: out_of_scope    | score=0.373, margin=0.164 [blocked] (R_NO_CONFIDENT_DETECTOR)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[13] brief me on the maintenance activities from last month\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.520 (ABSTAINED)\n",
      "LEVEL 1A: summarization   | conf=0.445 [needs_clarification] (ambiguous_prediction)\n",
      "LEVEL 1B: out_of_scope    | score=0.378, margin=0.165 [blocked] (R_NO_CONFIDENT_DETECTOR)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[14] what were the key events in today's deployment\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.448 (ABSTAINED)\n",
      "LEVEL 1A: out_of_scope    | conf=0.266 [needs_clarification] (ambiguous_prediction)\n",
      "LEVEL 1B: out_of_scope    | score=0.255, margin=0.012 [blocked] (R_NO_CONFIDENT_DETECTOR)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[15] can you sum up the performance issues we saw\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.412 (ABSTAINED)\n",
      "LEVEL 1A: investigate     | conf=0.319 [blocked] (insufficient_tokens)\n",
      "LEVEL 1B: out_of_scope    | score=0.296, margin=0.075 [blocked] (R_LOW_TOKEN_COUNT)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[16] good morning\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.478 (ABSTAINED)\n",
      "LEVEL 1A: out_of_scope    | conf=0.330 [blocked] (insufficient_tokens)\n",
      "LEVEL 1B: out_of_scope    | score=0.293, margin=0.057 [blocked] (R_LOW_TOKEN_COUNT)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[17] what's the recipe for chocolate chip cookies\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.478 (ABSTAINED)\n",
      "LEVEL 1A: out_of_scope    | conf=0.330 [blocked] (insufficient_tokens)\n",
      "LEVEL 1B: out_of_scope    | score=0.293, margin=0.057 [blocked] (R_LOW_TOKEN_COUNT)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[18] who's the current CEO of Microsoft\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.478 (ABSTAINED)\n",
      "LEVEL 1A: out_of_scope    | conf=0.330 [blocked] (insufficient_tokens)\n",
      "LEVEL 1B: out_of_scope    | score=0.293, margin=0.057 [blocked] (R_LOW_TOKEN_COUNT)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[19] explain how photosynthesis works\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.478 (ABSTAINED)\n",
      "LEVEL 1A: out_of_scope    | conf=0.493 [blocked] (insufficient_tokens)\n",
      "LEVEL 1B: out_of_scope    | score=0.424, margin=0.223 [blocked] (R_LOW_TOKEN_COUNT)\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[20] what's trending on social media today\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "LEVEL 0 : unknown         | conf=0.478 (ABSTAINED)\n",
      "LEVEL 1A: out_of_scope    | conf=0.402 [blocked] (insufficient_tokens)\n",
      "LEVEL 1B: out_of_scope    | score=0.366, margin=0.151 [blocked] (R_LOW_TOKEN_COUNT)\n",
      "\n",
      "============================================================================================================================================\n",
      "COMPARISON COMPLETE\n",
      "============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display detailed comparison without ground truth\n",
    "print('='*140)\n",
    "print('COMPREHENSIVE 3-MODEL COMPARISON (NO GROUND TRUTH)')\n",
    "print('='*140)\n",
    "\n",
    "for idx, row in results_df.iterrows():\n",
    "    print(f\"\\n{'-'*140}\")\n",
    "    print(f\"[{idx+1}] {row['utterance']}\")\n",
    "    print(f\"{'-'*140}\")\n",
    "    \n",
    "    # Level 0\n",
    "    l0_status = ' (ABSTAINED)' if row['l0_abstained'] else ''\n",
    "    print(f\"LEVEL 0 : {row['l0_intent']:15s} | conf={row['l0_confidence']:.3f}{l0_status}\")\n",
    "    \n",
    "    # Level 1A\n",
    "    l1a_status = f\" [{row['l1a_decision_state']}] ({row['l1a_decision_reason']})\"\n",
    "    print(f\"LEVEL 1A: {row['l1a_intent']:15s} | conf={row['l1a_confidence']:.3f}{l1a_status}\")\n",
    "    \n",
    "    # Level 1B\n",
    "    l1b_status = f\" [{row['l1b_decision_state']}] ({row['l1b_decision_reason']})\"\n",
    "    print(f\"LEVEL 1B: {row['l1b_intent']:15s} | score={row['l1b_top_score']:.3f}, margin={row['l1b_score_margin']:.3f}{l1b_status}\")\n",
    "\n",
    "print(f\"\\n{'='*140}\")\n",
    "print('COMPARISON COMPLETE')\n",
    "print('='*140)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5ac149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY (NO GROUND TRUTH)\n",
      "================================================================================\n",
      "\n",
      "Total test examples: 20\n",
      "\n",
      "Level 0 (Baseline):\n",
      "  Abstained: 17 (85.0%)\n",
      "\n",
      "Level 1A (Multi-Class + Rules):\n",
      "  Blocked:       8 (40.0%)\n",
      "  Needs Clarif:  10 (50.0%)\n",
      "\n",
      "Level 1B (Multi-Detector + Rule Types):\n",
      "  Blocked:       18 (90.0%)\n",
      "  Needs Clarif:  0 (0.0%)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary counts (no accuracy since no ground truth)\n",
    "l0_abstain_count = sum(results_df['l0_abstained'])\n",
    "l1a_blocked = sum(results_df['l1a_decision_state'] == 'blocked')\n",
    "l1a_clarify = sum(results_df['l1a_decision_state'] == 'needs_clarification')\n",
    "l1b_blocked = sum(results_df['l1b_decision_state'] == 'blocked')\n",
    "l1b_clarify = sum(results_df['l1b_decision_state'] == 'needs_clarification')\n",
    "\n",
    "total = len(results_df)\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('SUMMARY (NO GROUND TRUTH)')\n",
    "print('='*80)\n",
    "print(f'\\nTotal test examples: {total}')\n",
    "print()\n",
    "print(f'Level 0 (Baseline):')\n",
    "print(f'  Abstained: {l0_abstain_count} ({l0_abstain_count/total*100:.1f}%)')\n",
    "print()\n",
    "print(f'Level 1A (Multi-Class + Rules):')\n",
    "print(f'  Blocked:       {l1a_blocked} ({l1a_blocked/total*100:.1f}%)')\n",
    "print(f'  Needs Clarif:  {l1a_clarify} ({l1a_clarify/total*100:.1f}%)')\n",
    "print()\n",
    "print(f'Level 1B (Multi-Detector + Rule Types):')\n",
    "print(f'  Blocked:       {l1b_blocked} ({l1b_blocked/total*100:.1f}%)')\n",
    "print(f'  Needs Clarif:  {l1b_clarify} ({l1b_clarify/total*100:.1f}%)')\n",
    "print('='*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00186852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Results saved to validation_results.csv\n",
      "\n",
      "Columns: ['utterance', 'l0_intent', 'l0_confidence', 'l0_abstained', 'l1a_intent', 'l1a_decision_state', 'l1a_decision_reason', 'l1a_confidence', 'l1b_intent', 'l1b_decision_state', 'l1b_decision_reason', 'l1b_top_score', 'l1b_score_margin', 'l1b_decision_trace']\n"
     ]
    }
   ],
   "source": [
    "# Save comparison results\n",
    "results_df.to_csv('validation_results.csv', index=False)\n",
    "print('✓ Results saved to validation_results.csv')\n",
    "print(f\"\\nColumns: {list(results_df.columns)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
